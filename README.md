# Genrl
## Introduction
We introduce Generative Reinforcement Learning (Genrl), a **model-free** and **value-function-free** reinforcement learning method, where **only** neural networks are involved.

Our previous research can be seen in this [paper](https://ala2022.github.io/papers/ALA2022_paper_4.pdf), where we simply used supervised learning method rather than reinforcement learning method.

However, in Genrl, we have inherited the spirit of the previous researc while incorporating the concept of reinforcement learning, allowing the agent to learn from the results of it deduced actions. This enables the agent to find the optimal solution to achieve the maximum reward in the environment more quickly.

## Features
- **Neural Nets are all you need**: No need for the Bellman function, and none of the complicated jargon found in current deep reinforcement learning methods.
- **Highly custimizable**: All you need to do is to customize state, action and reward-shaping or vectorizing.

## Status
The project is currently in active development. We are continually adding new features and improving the performance.

## Getting Started
To get started with Genrl, follow these steps:

1. **Open the .ipynb in colab**
2. **Ctrl + F10**
3. **Take a rest and wait for the result**
